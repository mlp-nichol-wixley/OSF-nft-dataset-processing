{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe311c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49b7efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer = torch.nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)      \n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6549e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d6fb2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "DIR = os.getcwd() + \"/data/\"\n",
    "xx = np.load(DIR + \"xx.npy\")\n",
    "yy = np.load(DIR + \"yy.npy\")\n",
    "size = int(np.sqrt(xx.shape[1]))\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20c337a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(xx).float()\n",
    "y = torch.from_numpy(yy).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ce5959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([681, 1, 7, 7])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3cc41113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b338dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96f8a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Data loader\n",
    "train_iterator = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "val_iterator = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_iterator = DataLoader(dataset=test_dataset, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0db590b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train': train_iterator,\n",
    "    'val': val_iterator,\n",
    "    'test': test_iterator\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9acfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b91ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "065eae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ROC\n",
    "\n",
    "def eval_cnn(data):\n",
    "    \n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        pred_ys = []\n",
    "        labs = []\n",
    "        for images, labels in loaders[data]:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            pred_ys = pred_ys + test_output.flatten().tolist()\n",
    "            labs = labs + labels.tolist()\n",
    "            total += len(labels)\n",
    "            print(pred_y)\n",
    "            print(labels)\n",
    "            correct += (pred_y == labels).sum().item()\n",
    "            pass\n",
    "        print(f'{data} Accuracy of the model on the {total} {data} images: %.3f' % (correct/total))\n",
    "        return pred_ys, labs, correct/total\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e3ae9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        ).to(device)\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        ).to(device)\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(32, 64, 5, 1, 2),     \n",
    "            nn.ReLU()               \n",
    "        ).to(device)\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(64, 2).to(device)\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d20683b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b819cf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = nn.MSELoss()  \n",
    "loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6deccc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.001)   \n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0ecd2e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/4], Loss: nan\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[ 0.0000e+00,  7.6754e+05],\n",
      "        [ 0.0000e+00,  5.4000e+01],\n",
      "        [ 5.8333e-01,  1.6427e+04],\n",
      "        [ 6.6667e-02,  1.1149e+06],\n",
      "        [ 0.0000e+00,  2.9676e+06],\n",
      "        [-6.1538e-01,  9.8070e+05],\n",
      "        [ 1.0000e+00,  6.4400e+03],\n",
      "        [-1.3333e-01,  1.3973e+04],\n",
      "        [ 0.0000e+00,  1.4112e+04],\n",
      "        [ 5.7143e-02,  3.2070e+03],\n",
      "        [-1.0000e-01,  2.9686e+05],\n",
      "        [ 1.6087e+00,  1.2963e+05],\n",
      "        [ 1.6000e+00,  4.8029e+04],\n",
      "        [ 0.0000e+00,  8.2359e+04],\n",
      "        [-2.0000e-01,  3.2920e+05],\n",
      "        [-1.6667e-01,  5.8080e+03],\n",
      "        [-5.0000e-01,  8.1881e+04],\n",
      "        [ 1.0000e+00,  2.1770e+03],\n",
      "        [-5.0000e-01,  1.6624e+05],\n",
      "        [ 1.0000e-01,  2.6837e+05],\n",
      "        [ 0.0000e+00,  4.1445e+04],\n",
      "        [ 2.5000e-01,  2.6475e+05],\n",
      "        [-5.8824e-02,  2.8275e+05],\n",
      "        [-5.0000e-01,  2.2210e+03],\n",
      "        [ 0.0000e+00,  1.6200e+02],\n",
      "        [ 0.0000e+00,  1.0291e+05],\n",
      "        [ 0.0000e+00,  1.3113e+05],\n",
      "        [-4.3750e-01,  1.1087e+04],\n",
      "        [-9.9500e-01,  1.1469e+05],\n",
      "        [-7.9378e-01,  1.2202e+05],\n",
      "        [ 9.0000e+00,  4.3439e+05],\n",
      "        [ 1.5145e+01,  9.4073e+04],\n",
      "        [-7.7791e-01,  3.1256e+04],\n",
      "        [-9.9110e-01,  1.0740e+03],\n",
      "        [ 1.0000e+00,  2.0000e+00],\n",
      "        [ 0.0000e+00,  2.9764e+04],\n",
      "        [ 0.0000e+00,  1.8600e+03],\n",
      "        [-7.8182e-01,  3.0153e+05],\n",
      "        [ 0.0000e+00,  2.3776e+05],\n",
      "        [ 0.0000e+00,  1.7870e+03],\n",
      "        [ 0.0000e+00,  6.0500e+02],\n",
      "        [ 0.0000e+00,  1.4540e+05],\n",
      "        [ 5.4000e-01,  4.7345e+05],\n",
      "        [-4.4444e-01,  7.6210e+04],\n",
      "        [ 0.0000e+00,  4.6491e+04],\n",
      "        [ 0.0000e+00,  1.2013e+04],\n",
      "        [ 0.0000e+00,  9.8219e+04],\n",
      "        [-1.4286e-01,  2.3151e+04],\n",
      "        [ 2.0000e+00,  4.6131e+04],\n",
      "        [ 2.0408e-02,  4.7240e+04],\n",
      "        [-1.6949e-02,  3.1937e+04],\n",
      "        [-8.5017e-01,  6.0093e+04],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  7.9580e+04],\n",
      "        [ 0.0000e+00,  1.8880e+05],\n",
      "        [-5.0000e-01,  1.5260e+04],\n",
      "        [ 0.0000e+00,  1.4496e+04],\n",
      "        [ 0.0000e+00,  2.3520e+03],\n",
      "        [ 0.0000e+00,  4.5794e+05],\n",
      "        [ 0.0000e+00,  3.7400e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  1.4121e+04],\n",
      "        [ 0.0000e+00,  4.5780e+03],\n",
      "        [ 7.5000e-02,  1.4434e+05],\n",
      "        [ 0.0000e+00,  6.9480e+03],\n",
      "        [ 1.1111e-01,  4.4512e+05],\n",
      "        [ 9.0000e+00,  1.7980e+03],\n",
      "        [ 1.2000e-01,  4.3687e+04],\n",
      "        [-6.6667e-01,  5.5934e+05],\n",
      "        [-4.0798e-01,  2.2150e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [-5.0000e-01,  1.6000e+01],\n",
      "        [ 0.0000e+00,  1.4351e+04],\n",
      "        [ 0.0000e+00,  6.0035e+04],\n",
      "        [ 9.9355e-02,  7.0505e+04],\n",
      "        [ 3.2667e-01,  2.1830e+03],\n",
      "        [ 0.0000e+00,  1.2528e+05],\n",
      "        [ 2.9286e+00,  2.6000e+01],\n",
      "        [ 0.0000e+00,  1.6600e+02],\n",
      "        [ 4.2553e-03,  5.0800e+02],\n",
      "        [ 2.0000e-01,  1.8010e+03],\n",
      "        [ 3.7681e-01,  3.0370e+04],\n",
      "        [-5.0000e-01,  2.3800e+02],\n",
      "        [ 0.0000e+00,  1.4097e+04],\n",
      "        [ 0.0000e+00,  1.9450e+06],\n",
      "        [ 0.0000e+00,  3.1000e+01],\n",
      "        [ 0.0000e+00,  4.5000e+03],\n",
      "        [ 2.0000e-01,  5.4859e+05],\n",
      "        [ 0.0000e+00,  3.4610e+03],\n",
      "        [-6.4286e-01,  1.1552e+06],\n",
      "        [ 0.0000e+00,  1.4528e+04],\n",
      "        [ 9.0909e-02,  5.4460e+03],\n",
      "        [ 1.2000e+00,  8.1088e+05],\n",
      "        [-7.6800e-01,  1.0000e+00],\n",
      "        [ 0.0000e+00,  4.1235e+05],\n",
      "        [ 0.0000e+00,  2.1592e+05],\n",
      "        [ 1.0000e+00,  2.1000e+01],\n",
      "        [ 0.0000e+00,  6.2600e+02],\n",
      "        [ 0.0000e+00,  2.6914e+04],\n",
      "        [ 0.0000e+00,  4.7460e+04],\n",
      "        [ 0.0000e+00,  1.3963e+04],\n",
      "        [ 3.3333e-01,  3.3300e+02],\n",
      "        [ 0.0000e+00,  1.0610e+03],\n",
      "        [ 0.0000e+00,  3.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [-9.9274e-01,  2.1142e+06],\n",
      "        [ 1.6667e-01,  9.0850e+03],\n",
      "        [-5.5556e-01,  1.0914e+05],\n",
      "        [-6.1905e-01,  1.3655e+06],\n",
      "        [ 0.0000e+00,  5.2140e+03],\n",
      "        [-3.3333e-01,  4.6282e+05],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  1.5000e+01],\n",
      "        [ 2.5000e-01,  5.1414e+05],\n",
      "        [-5.5556e-01,  2.2807e+04],\n",
      "        [ 4.6127e+00,  8.8011e+04],\n",
      "        [ 1.5000e+00,  1.4867e+06],\n",
      "        [ 0.0000e+00,  5.4289e+04],\n",
      "        [-5.0000e-01,  0.0000e+00],\n",
      "        [ 1.1600e+02,  5.2677e+06],\n",
      "        [-4.3776e-01,  3.3900e+02],\n",
      "        [ 0.0000e+00,  1.4700e+02],\n",
      "        [-7.5000e-01,  1.4000e+02],\n",
      "        [ 0.0000e+00,  7.8090e+03],\n",
      "        [ 0.0000e+00,  4.9614e+04],\n",
      "        [ 0.0000e+00,  2.9000e+01],\n",
      "        [ 0.0000e+00,  8.6280e+03],\n",
      "        [-8.0000e-01,  9.5290e+03]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_176753/1172737325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_176753/1172737325.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, cnn, loaders)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 cnn_epochs[epoch] = {\"loss\": loss.item(), \"train\": eval_cnn(\"train\"), \n\u001b[0m\u001b[1;32m     36\u001b[0m                              \"val\": eval_cnn(\"val\"), \"test\": eval_cnn(\"test\")}\n\u001b[1;32m     37\u001b[0m                 \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_176753/3983508442.py\u001b[0m in \u001b[0;36meval_cnn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data} Accuracy of the model on the {total} {data} images: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "num_epochs = 10\n",
    "cnn_epochs = {}\n",
    "\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    #print(\"hello\")\n",
    "    cnn.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "    #print(1)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            #print(0)\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)   # batch x\n",
    "            b_y = Variable(labels)   # batch y\n",
    "            output = cnn(b_x)[0]               \n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()                \n",
    "            \n",
    "            if (i+1) % 1 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "                cnn_epochs[epoch] = {\"loss\": loss.item(), \"train\": eval_cnn(\"train\"), \n",
    "                             \"val\": eval_cnn(\"val\"), \"test\": eval_cnn(\"test\")}\n",
    "                cnn.train()\n",
    "                pass\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "train(num_epochs, cnn, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe945cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7*7*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4e72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0ada7a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "82f6c6bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_176753/3893913333.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    792\u001b[0m                 ) from e\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    795\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c25bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
